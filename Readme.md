# Sarlacc
Named after the giant pit monster that quickly eats anything, this is an experiment in quickly ingesting and processing data using the Play Framework. It provides data ingestion and basic aggregation features at blazing speeds.

The general approach uses a large ring bufer full of mutable data cells to avoid heap allocation & the corresponding GC. To manage this structure there are three atomic integers, a read pointer, write pointer, & counter. The read and write pointers are used to control which index is acted upon by a read or write operation, while the counter tracks how far ahead the write pointer has gotten. In the event that the write pointer has wrapped around the ring buffer & catches up with the read head, it will block. Because of this behavior, it is important to allocate enough cells in the buffer for the workload in question.

Because the ring buffer uses atomic integers to maintain its indexes, sarlacc is able to take full advantage of Play's scalable connection handling by accepting thousands of connections/sec. Avoiding unnecessary intermediate objects is a major part of how I achieve high performance, and in that vein I've elected not to translate the raw JSON into actual scala domain objects, but rather parse it into simple tuples (this could be even more efficient if the `offer` function were exposed directly to the controller).

On the data processing side its most efficient to use a single thread for aggregation as the workload is tiny & the parallelism overhead would be overwhelming. This single thread is used to maintain a leading-edge aggregation that rolls every `n` minutes, and on the hour. An hourly roll produces a snapshot file of the past hour's aggregation data, which allows me to quickly reduce the past `m` hours worth of data into a single aggregation, then apply the leading edge on top of it. 
